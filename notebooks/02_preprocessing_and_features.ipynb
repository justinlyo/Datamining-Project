{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b68970",
   "metadata": {},
   "source": [
    "# 02 - Preprocessing and Feature Selection\n",
    "\n",
    "In this notebook, we define the preprocessing steps and will pick the audio features that will be used for clustering. We will avoid redoing the full analysis from the previous notebook and focus on:\n",
    "\n",
    "* Dropping duplicates and rows with missing values\n",
    "* Selecting certain audio features for clustering\n",
    "* Demonstrating feature scaling with StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc6046e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5SuOikwiRyPMVoIQDJUgSV</td>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.4610</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.715</td>\n",
       "      <td>87.917</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4qPNDBW1i3p13qLCt0Ki3A</td>\n",
       "      <td>Ben Woodward</td>\n",
       "      <td>Ghost (Acoustic)</td>\n",
       "      <td>Ghost - Acoustic</td>\n",
       "      <td>55</td>\n",
       "      <td>149610</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.267</td>\n",
       "      <td>77.489</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1iJBSr7s7jYXzM8EGcbK5b</td>\n",
       "      <td>Ingrid Michaelson;ZAYN</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>57</td>\n",
       "      <td>210826</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.120</td>\n",
       "      <td>76.332</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6lfxq3CG4xtTiEg7opyCyx</td>\n",
       "      <td>Kina Grannis</td>\n",
       "      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>\n",
       "      <td>Can't Help Falling In Love</td>\n",
       "      <td>71</td>\n",
       "      <td>201933</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.143</td>\n",
       "      <td>181.740</td>\n",
       "      <td>3</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5vjLSffimiIP26QG5WcN2K</td>\n",
       "      <td>Chord Overstreet</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>Hold On</td>\n",
       "      <td>82</td>\n",
       "      <td>198853</td>\n",
       "      <td>False</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.681</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.167</td>\n",
       "      <td>119.949</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                track_id                 artists  \\\n",
       "0           0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
       "1           1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
       "2           2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
       "3           3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
       "4           4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
       "\n",
       "                                          album_name  \\\n",
       "0                                             Comedy   \n",
       "1                                   Ghost (Acoustic)   \n",
       "2                                     To Begin Again   \n",
       "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
       "4                                            Hold On   \n",
       "\n",
       "                   track_name  popularity  duration_ms  explicit  \\\n",
       "0                      Comedy          73       230666     False   \n",
       "1            Ghost - Acoustic          55       149610     False   \n",
       "2              To Begin Again          57       210826     False   \n",
       "3  Can't Help Falling In Love          71       201933     False   \n",
       "4                     Hold On          82       198853     False   \n",
       "\n",
       "   danceability  energy  ...  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.676  0.4610  ...    -6.746     0       0.1430        0.0322   \n",
       "1         0.420  0.1660  ...   -17.235     1       0.0763        0.9240   \n",
       "2         0.438  0.3590  ...    -9.734     1       0.0557        0.2100   \n",
       "3         0.266  0.0596  ...   -18.515     1       0.0363        0.9050   \n",
       "4         0.618  0.4430  ...    -9.681     1       0.0526        0.4690   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  time_signature  track_genre  \n",
       "0          0.000001    0.3580    0.715   87.917               4     acoustic  \n",
       "1          0.000006    0.1010    0.267   77.489               4     acoustic  \n",
       "2          0.000000    0.1170    0.120   76.332               4     acoustic  \n",
       "3          0.000071    0.1320    0.143  181.740               3     acoustic  \n",
       "4          0.000000    0.0829    0.167  119.949               4     acoustic  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "DATASET_PATH = Path(\"..\") / \"data\" / \"raw\" / \"spotify_tracks.csv\"\n",
    "\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d04f8b",
   "metadata": {},
   "source": [
    "## 1. Remove duplicates and handle missing values in certain audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "078e671a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries in dataset: 114000\n",
      "Duplicate count: 0\n"
     ]
    }
   ],
   "source": [
    "len_before = len(df)\n",
    "dup_count = df.duplicated().sum()\n",
    "print(f\"Entries in dataset: {len_before}\\nDuplicate count: {int(dup_count)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81aeee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries in dataset before: 114000\n",
      "Entries in dataset after: 114000\n"
     ]
    }
   ],
   "source": [
    "# Drop any duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "len_after = len(df)\n",
    "print(f\"Entries in dataset before: {len_before}\\nEntries in dataset after: {len_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b37dcdc",
   "metadata": {},
   "source": [
    "### Select audio feature columns\n",
    "\n",
    "We will select the Spotify audio features that will be used as input to the clustering algorithm. These values are numeric and describe the sound, not labels such as popularity or genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d0d19dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['danceability',\n",
       "  'energy',\n",
       "  'loudness',\n",
       "  'speechiness',\n",
       "  'acousticness',\n",
       "  'instrumentalness',\n",
       "  'liveness',\n",
       "  'valence',\n",
       "  'tempo',\n",
       "  'duration_ms'],\n",
       " [])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_feature_columns = [\n",
    "    \"danceability\",\n",
    "    \"energy\",\n",
    "    \"loudness\",\n",
    "    \"speechiness\",\n",
    "    \"acousticness\",\n",
    "    \"instrumentalness\",\n",
    "    \"liveness\",\n",
    "    \"valence\",\n",
    "    \"tempo\",\n",
    "    \"duration_ms\",\n",
    "]\n",
    "\n",
    "# We will only get features that are in the dataset columns\n",
    "available_features = [c for c in audio_feature_columns if c in df.columns]\n",
    "missing_features = [c for c in audio_feature_columns if c not in df.columns]\n",
    "\n",
    "available_features, missing_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "991109ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length before cleaning: 114000\n",
      "Length after cleaning: 114000\n"
     ]
    }
   ],
   "source": [
    "# Drop any rows that are not part of the selected audio features\n",
    "len_before_na = len(df)\n",
    "df_clean = df.dropna(subset=available_features)\n",
    "len_after_na = len(df_clean)\n",
    "print(f\"Length before cleaning: {len_before_na}\\nLength after cleaning: {len_after_na}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd87e53d",
   "metadata": {},
   "source": [
    "We can see that there is no change with the cleaning. This just means that all of our audio feature columns are also in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367afa6c",
   "metadata": {},
   "source": [
    "## 2. Prepare feature matrix and apply scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7af4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.62924424, -0.71714792,  0.30082834,  0.55184753, -0.85020151,\n",
       "        -0.50410861,  0.75874327,  0.92930586, -1.14186279,  0.02457516],\n",
       "       [-0.84590798, -1.88997974, -1.78474412, -0.07899331,  1.8317324 ,\n",
       "        -0.50409391, -0.59121068, -0.79868969, -1.48971712, -0.73085898],\n",
       "       [-0.74218634, -1.12266943, -0.2932884 , -0.27382571, -0.31549883,\n",
       "        -0.50411187, -0.50716686, -1.36568823, -1.528312  , -0.16033174]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_clean[audio_feature_columns].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_scaled[:3] # Output the first few rows of the scaled feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6621bd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.06879209e-16, -2.11417628e-16, -1.27648379e-16,  7.97802370e-18,\n",
       "        -9.57362844e-17, -1.59560474e-17,  1.13686838e-16,  1.59560474e-16,\n",
       "        -4.98626481e-16,  2.19395652e-17]),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check approximate means and standard deviations after scaling\n",
    "import numpy as np\n",
    "np.mean(X_scaled, axis=0), np.std(X_scaled, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebdade0",
   "metadata": {},
   "source": [
    "This will scale them to have a mean very close to 0 and standard deviation close to 1. This is important since we are using K-Means with Euclidean distance so that features with larger ranges won't dominate the distance computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bce327",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook we:\n",
    "* Dropped duplicate rows from the raw dataset.\n",
    "* Pick a set of audio features for clustering: danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, tempo, and duration.\n",
    "* Removed rows with missing values in these features\n",
    "* Scaled the selected features using StandardScalar\n",
    "\n",
    "These steps match the preprocessing that will be implemnented in the project code and this will be a reference for how clustering input is constructed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotify-clustering-bewXrD72-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
